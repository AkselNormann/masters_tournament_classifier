{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, I attempt to use machine learning to predict whether or not a golfer will make the cut at the Masters Tournament. The models used take inputs consisting of full season aggregate statistics from the previous year to make the predictions for that year's Masters Tournament (e.g., the models used 2018 full season data to predict 2019 results.\n",
    "\n",
    "Additionally, we will use the subset of golfers that make the cut to attempt to predict the top 10 come Sunday evening at Augusta using the same inputs as before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary Packages and Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/JacquesPierre/anaconda3/envs/tf/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Webscrapping\n",
    "from urllib.request import urlopen as uReq\n",
    "from bs4 import BeautifulSoup as soup\n",
    "\n",
    "# Sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Class imbalance\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import RandomOverSampler as ROS\n",
    "\n",
    "# Graphing\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "figsize = (15,10)\n",
    "hspace = 0.5\n",
    "\n",
    "# Pickling\n",
    "import pickle\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Webscrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PGATour.com Webscrapping Function\n",
    "def get_PGA_Tour_data(stats, seasons):\n",
    "\n",
    "    \"\"\"\n",
    "    This function pings the PGA Tour's server and gathers the desired statistics\n",
    "    (by inserting the stat_id into the url) and appends it to our data container\n",
    "    \"\"\"\n",
    "\n",
    "    data = []\n",
    "    \n",
    "    for season in seasons:  \n",
    "        print(f\"Beginning {season} season:\")\n",
    "        for stat in stats: \n",
    "            url = f\"https://www.pgatour.com/content/pgatour/stats/stat.{stat['stat_id']}.y{season}.html\"\n",
    "\n",
    "            #opening up connection, grabbing the page\n",
    "            uClient = uReq(url)\n",
    "            page_html = uClient.read()\n",
    "\n",
    "            #html parsing using BeautifulSoup\n",
    "            page_soup = soup(page_html, 'html.parser')\n",
    "\n",
    "            #find the table where stats are kept\n",
    "            tbody = page_soup.find('tbody')\n",
    "\n",
    "            #each golfer is separated by a <tr> tag\n",
    "            raw_golfers = tbody.findAll('tr')\n",
    "\n",
    "            #loop through each golfer, grab name and avg. distance\n",
    "            for raw_golfer in raw_golfers:\n",
    "                golfer = {}\n",
    "                golfer['season'] = season            \n",
    "                name = raw_golfer.find('td', {'class':'player-name'}).a.text\n",
    "                golfer['full_name'] = name.replace(' ', '_').lower()\n",
    "                golfer[f\"{stat['stat_name']}\"] = raw_golfer.find('td', {'class':None}).text\n",
    "                data.append(golfer)\n",
    "            print(f\" {stat['stat_name']} stats added for the {season} season\")\n",
    "        print(f\"{season} season completed.\\n\")\n",
    "\n",
    "    #close the client\n",
    "    uClient.close()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert Strings to Feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert stats to feet function\n",
    "def convert_to_feet(x):\n",
    "    \"\"\"\n",
    "    This function takes in a string and returns a float\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(x) == str:\n",
    "        y = x.replace(\"'\",\"\").replace('\"',\"\").split()\n",
    "\n",
    "        if len(y) == 1:\n",
    "            y.extend([0])\n",
    "            for i in range(len(y)):\n",
    "                y[i] = int(y[i])\n",
    "            return y[0]+(y[1]/12)\n",
    "\n",
    "        else:\n",
    "            for i in range(len(y)):\n",
    "                y[i] = int(y[i])\n",
    "            return y[0]+(y[1]/12)\n",
    "\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Format Golfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format golfer names from results Dataframe\n",
    "def format_golfer(x):\n",
    "    return x.replace(' ','_').lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotter Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates the confusion matrix\n",
    "def plot_confusion_matrix(cm, classes):\n",
    "    cmap = plt.cm.Blues\n",
    "    fig = plt.figure(figsize=(5,4));\n",
    "    ax = fig.add_subplot(111);\n",
    "    cax = ax.matshow(cm, cmap=cmap);\n",
    "    fig.colorbar(cax);\n",
    "    ax.set_xticklabels([''] + classes);\n",
    "    ax.set_yticklabels([''] + classes);\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], 'd'), {\n",
    "            'fontsize' : 18,\n",
    "            'horizontalalignment' : \"center\",\n",
    "            'verticalalignment' : \"center\"\n",
    "        }, color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "\n",
    "    plt.xlabel('Predicted');\n",
    "    plt.ylabel('Actual') ;\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Importance Plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates feature importance graphs\n",
    "def plot_feature_importances(X_train, model, n_features, FI_labels):\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.barh(range(n_features), model.feature_importances_, align='center') \n",
    "    plt.yticks(np.arange(n_features), FI_labels) \n",
    "    plt.xlabel('Feature Importance')\n",
    "    plt.ylabel('Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Gathering and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Gathering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Desired Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # The stat_id will be inserted into the url for each ping\n",
    "# stats = [\n",
    "#     {'stat_name': 'driving_distance',\n",
    "#      'stat_id': '101'},\n",
    "#     {'stat_name': 'driving_accuracy', \n",
    "#      'stat_id': '102'},\n",
    "#     {'stat_name': 'greens_in_regulation', \n",
    "#      'stat_id': '103'},\n",
    "#     {'stat_name': 'proximity', \n",
    "#      'stat_id': '331'},\n",
    "#     {'stat_name': 'scrambling_rough',  \n",
    "#      'stat_id': '363'},\n",
    "#     {'stat_name': 'scrambling_sand',  \n",
    "#      'stat_id': '362'},\n",
    "#     {'stat_name': 'putting_conversion',\n",
    "#      'stat_id': '115'},\n",
    "#     {'stat_name': 'putting_rating',\n",
    "#      'stat_id': '402'},\n",
    "#     {'stat_name': 'sg_off_tee',\n",
    "#      'stat_id': '02567'},\n",
    "#     {'stat_name': 'sg_approach',\n",
    "#      'stat_id': '02568'},\n",
    "#     {'stat_name': 'sg_scrambling',  \n",
    "#      'stat_id': '02569'},\n",
    "#     {'stat_name': 'sg_putting',\n",
    "#      'stat_id': '02564'},\n",
    "#     {'stat_name': 'sg_tee_to_green',  \n",
    "#      'stat_id': '02674'},\n",
    "#     {'stat_name': 'sg_total',  \n",
    "#      'stat_id': '02675'},\n",
    "#     {'stat_name': 'scoring_avg',  \n",
    "#      'stat_id': '120'},\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Seasons Considered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Since strokes_gained stats only go back to 2004, we will consider 2004-2019\n",
    "# seasons = range(2004, 2020)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Webscrapping and Dataframe Conversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Call the web scrapping helper function defined above. Save the results and examine Dataframe\n",
    "# data = get_PGA_Tour_data(stats, seasons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Convert data to Dataframe and save raw data locally\n",
    "# df = pd.DataFrame(data)\n",
    "# df.to_csv('csv_files/raw_golfer_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groupby Season and Golfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48592, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>full_name</th>\n",
       "      <th>driving_distance</th>\n",
       "      <th>driving_accuracy</th>\n",
       "      <th>greens_in_regulation</th>\n",
       "      <th>proximity</th>\n",
       "      <th>scrambling_rough</th>\n",
       "      <th>scrambling_sand</th>\n",
       "      <th>putting_conversion</th>\n",
       "      <th>putting_rating</th>\n",
       "      <th>sg_off_tee</th>\n",
       "      <th>sg_approach</th>\n",
       "      <th>sg_scrambling</th>\n",
       "      <th>sg_putting</th>\n",
       "      <th>sg_tee_to_green</th>\n",
       "      <th>sg_total</th>\n",
       "      <th>scoring_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>hank_kuehne</td>\n",
       "      <td>314.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>scott_hend</td>\n",
       "      <td>312.6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>john_daly</td>\n",
       "      <td>306.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>mike_heinen</td>\n",
       "      <td>305.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>chris_smith</td>\n",
       "      <td>304.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season    full_name  driving_distance  driving_accuracy  \\\n",
       "0    2004  hank_kuehne             314.4               NaN   \n",
       "1    2004   scott_hend             312.6               NaN   \n",
       "2    2004    john_daly             306.0               NaN   \n",
       "3    2004  mike_heinen             305.2               NaN   \n",
       "4    2004  chris_smith             304.0               NaN   \n",
       "\n",
       "   greens_in_regulation proximity  scrambling_rough  scrambling_sand  \\\n",
       "0                   NaN       NaN               NaN              NaN   \n",
       "1                   NaN       NaN               NaN              NaN   \n",
       "2                   NaN       NaN               NaN              NaN   \n",
       "3                   NaN       NaN               NaN              NaN   \n",
       "4                   NaN       NaN               NaN              NaN   \n",
       "\n",
       "   putting_conversion  putting_rating  sg_off_tee  sg_approach  sg_scrambling  \\\n",
       "0                 NaN             NaN         NaN          NaN            NaN   \n",
       "1                 NaN             NaN         NaN          NaN            NaN   \n",
       "2                 NaN             NaN         NaN          NaN            NaN   \n",
       "3                 NaN             NaN         NaN          NaN            NaN   \n",
       "4                 NaN             NaN         NaN          NaN            NaN   \n",
       "\n",
       "   sg_putting  sg_tee_to_green  sg_total  scoring_avg  \n",
       "0         NaN              NaN       NaN          NaN  \n",
       "1         NaN              NaN       NaN          NaN  \n",
       "2         NaN              NaN       NaN          NaN  \n",
       "3         NaN              NaN       NaN          NaN  \n",
       "4         NaN              NaN       NaN          NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload raw data and examine dataframe\n",
    "df = pd.read_csv('csv_files/raw_golfer_data.csv', index_col=0)\n",
    "df.drop('str_diff_to_field', axis=1, inplace=True)\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3036, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>full_name</th>\n",
       "      <th>driving_distance</th>\n",
       "      <th>driving_accuracy</th>\n",
       "      <th>greens_in_regulation</th>\n",
       "      <th>scrambling_rough</th>\n",
       "      <th>scrambling_sand</th>\n",
       "      <th>putting_conversion</th>\n",
       "      <th>putting_rating</th>\n",
       "      <th>sg_off_tee</th>\n",
       "      <th>sg_approach</th>\n",
       "      <th>sg_scrambling</th>\n",
       "      <th>sg_putting</th>\n",
       "      <th>sg_tee_to_green</th>\n",
       "      <th>sg_total</th>\n",
       "      <th>scoring_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>aaron_baddeley</td>\n",
       "      <td>288.0</td>\n",
       "      <td>53.08</td>\n",
       "      <td>58.17</td>\n",
       "      <td>57.69</td>\n",
       "      <td>53.51</td>\n",
       "      <td>30.15</td>\n",
       "      <td>1.576</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.579</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>71.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>adam_scott</td>\n",
       "      <td>295.4</td>\n",
       "      <td>57.65</td>\n",
       "      <td>65.60</td>\n",
       "      <td>53.01</td>\n",
       "      <td>61.70</td>\n",
       "      <td>32.90</td>\n",
       "      <td>1.611</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.603</td>\n",
       "      <td>1.427</td>\n",
       "      <td>70.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>alex_cejka</td>\n",
       "      <td>285.8</td>\n",
       "      <td>64.21</td>\n",
       "      <td>63.81</td>\n",
       "      <td>51.08</td>\n",
       "      <td>57.65</td>\n",
       "      <td>28.77</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.388</td>\n",
       "      <td>71.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>andre_stolz</td>\n",
       "      <td>297.9</td>\n",
       "      <td>58.97</td>\n",
       "      <td>63.00</td>\n",
       "      <td>46.32</td>\n",
       "      <td>52.44</td>\n",
       "      <td>28.38</td>\n",
       "      <td>1.628</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>-1.247</td>\n",
       "      <td>72.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>arjun_atwal</td>\n",
       "      <td>289.4</td>\n",
       "      <td>60.48</td>\n",
       "      <td>62.52</td>\n",
       "      <td>59.79</td>\n",
       "      <td>41.07</td>\n",
       "      <td>29.80</td>\n",
       "      <td>1.606</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>71.688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season       full_name  driving_distance  driving_accuracy  \\\n",
       "0    2004  aaron_baddeley             288.0             53.08   \n",
       "1    2004      adam_scott             295.4             57.65   \n",
       "2    2004      alex_cejka             285.8             64.21   \n",
       "3    2004     andre_stolz             297.9             58.97   \n",
       "4    2004     arjun_atwal             289.4             60.48   \n",
       "\n",
       "   greens_in_regulation  scrambling_rough  scrambling_sand  \\\n",
       "0                 58.17             57.69            53.51   \n",
       "1                 65.60             53.01            61.70   \n",
       "2                 63.81             51.08            57.65   \n",
       "3                 63.00             46.32            52.44   \n",
       "4                 62.52             59.79            41.07   \n",
       "\n",
       "   putting_conversion  putting_rating  sg_off_tee  sg_approach  sg_scrambling  \\\n",
       "0               30.15           1.576      -0.530       -0.679          0.201   \n",
       "1               32.90           1.611       0.180        0.571         -0.147   \n",
       "2               28.77           1.625       0.119        0.255          0.020   \n",
       "3               28.38           1.628      -0.333       -0.532         -0.137   \n",
       "4               29.80           1.606       0.013       -0.097         -0.116   \n",
       "\n",
       "   sg_putting  sg_tee_to_green  sg_total  scoring_avg  \n",
       "0       0.579           -1.008    -0.429       71.614  \n",
       "1       0.824            0.603     1.427       70.096  \n",
       "2      -0.006            0.394     0.388       71.153  \n",
       "3      -0.246           -1.002    -1.247       72.341  \n",
       "4      -0.034           -0.200    -0.234       71.688  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group stats by season and golfer\n",
    "df = df.groupby(['season', 'full_name'])[\n",
    "    'driving_distance',\n",
    "    'driving_accuracy',\n",
    "    'greens_in_regulation',\n",
    "    'proximity',\n",
    "    'scrambling_rough',\n",
    "    'scrambling_sand',\n",
    "    'putting_conversion',\n",
    "    'putting_rating',\n",
    "    'sg_off_tee',\n",
    "    'sg_approach',\n",
    "    'sg_scrambling',\n",
    "    'sg_putting',\n",
    "    'sg_tee_to_green',\n",
    "    'sg_total',\n",
    "    'scoring_avg'\n",
    "].mean()\n",
    "\n",
    "# Save grouped data locally\n",
    "df.to_csv('csv_files/golfer_data.csv')\n",
    "\n",
    "# Reload and examine data\n",
    "df = pd.read_csv('csv_files/golfer_data.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Missing Golfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(28, 17)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>full_name</th>\n",
       "      <th>driving_distance</th>\n",
       "      <th>driving_accuracy</th>\n",
       "      <th>greens_in_regulation</th>\n",
       "      <th>proximity</th>\n",
       "      <th>scrambling_rough</th>\n",
       "      <th>scrambling_sand</th>\n",
       "      <th>putting_conversion</th>\n",
       "      <th>putting_rating</th>\n",
       "      <th>sg_off_tee</th>\n",
       "      <th>sg_approach</th>\n",
       "      <th>sg_scrambling</th>\n",
       "      <th>sg_putting</th>\n",
       "      <th>sg_tee_to_green</th>\n",
       "      <th>sg_total</th>\n",
       "      <th>scoring_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007</td>\n",
       "      <td>andres_romero</td>\n",
       "      <td>312.5</td>\n",
       "      <td>56.25</td>\n",
       "      <td>58.89</td>\n",
       "      <td>33' 10\"</td>\n",
       "      <td>76.47</td>\n",
       "      <td>62.16</td>\n",
       "      <td>26.42</td>\n",
       "      <td>1.572</td>\n",
       "      <td>1.988</td>\n",
       "      <td>-0.457</td>\n",
       "      <td>0.342</td>\n",
       "      <td>0.416</td>\n",
       "      <td>1.873</td>\n",
       "      <td>2.289</td>\n",
       "      <td>68.653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2005</td>\n",
       "      <td>ángel_cabrera</td>\n",
       "      <td>311.2</td>\n",
       "      <td>53.30</td>\n",
       "      <td>63.33</td>\n",
       "      <td>37' 10\"</td>\n",
       "      <td>54.29</td>\n",
       "      <td>47.50</td>\n",
       "      <td>29.03</td>\n",
       "      <td>1.665</td>\n",
       "      <td>0.531</td>\n",
       "      <td>0.067</td>\n",
       "      <td>0.141</td>\n",
       "      <td>-0.136</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.603</td>\n",
       "      <td>70.669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019</td>\n",
       "      <td>c.t._pan</td>\n",
       "      <td>285.0</td>\n",
       "      <td>64.77</td>\n",
       "      <td>64.16</td>\n",
       "      <td>36' 7\"</td>\n",
       "      <td>58.39</td>\n",
       "      <td>57.45</td>\n",
       "      <td>28.98</td>\n",
       "      <td>1.595</td>\n",
       "      <td>-0.114</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.180</td>\n",
       "      <td>-0.062</td>\n",
       "      <td>0.120</td>\n",
       "      <td>0.059</td>\n",
       "      <td>70.966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010</td>\n",
       "      <td>charl_schwartzel</td>\n",
       "      <td>300.8</td>\n",
       "      <td>62.05</td>\n",
       "      <td>59.72</td>\n",
       "      <td>36' 0\"</td>\n",
       "      <td>55.88</td>\n",
       "      <td>63.64</td>\n",
       "      <td>29.65</td>\n",
       "      <td>1.615</td>\n",
       "      <td>-0.505</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.338</td>\n",
       "      <td>0.528</td>\n",
       "      <td>0.699</td>\n",
       "      <td>1.227</td>\n",
       "      <td>70.879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>charl_schwartzel</td>\n",
       "      <td>291.3</td>\n",
       "      <td>50.67</td>\n",
       "      <td>61.28</td>\n",
       "      <td>40' 11\"</td>\n",
       "      <td>70.51</td>\n",
       "      <td>56.06</td>\n",
       "      <td>30.11</td>\n",
       "      <td>1.583</td>\n",
       "      <td>-1.526</td>\n",
       "      <td>-0.025</td>\n",
       "      <td>0.234</td>\n",
       "      <td>0.407</td>\n",
       "      <td>-1.317</td>\n",
       "      <td>-0.910</td>\n",
       "      <td>72.117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season         full_name  driving_distance  driving_accuracy  \\\n",
       "0    2007     andres_romero             312.5             56.25   \n",
       "1    2005     ángel_cabrera             311.2             53.30   \n",
       "2    2019          c.t._pan             285.0             64.77   \n",
       "3    2010  charl_schwartzel             300.8             62.05   \n",
       "4    2019  charl_schwartzel             291.3             50.67   \n",
       "\n",
       "   greens_in_regulation proximity  scrambling_rough  scrambling_sand  \\\n",
       "0                 58.89   33' 10\"             76.47            62.16   \n",
       "1                 63.33   37' 10\"             54.29            47.50   \n",
       "2                 64.16    36' 7\"             58.39            57.45   \n",
       "3                 59.72    36' 0\"             55.88            63.64   \n",
       "4                 61.28   40' 11\"             70.51            56.06   \n",
       "\n",
       "   putting_conversion  putting_rating  sg_off_tee  sg_approach  sg_scrambling  \\\n",
       "0               26.42           1.572       1.988       -0.457          0.342   \n",
       "1               29.03           1.665       0.531        0.067          0.141   \n",
       "2               28.98           1.595      -0.114        0.054          0.180   \n",
       "3               29.65           1.615      -0.505        0.865          0.338   \n",
       "4               30.11           1.583      -1.526       -0.025          0.234   \n",
       "\n",
       "   sg_putting  sg_tee_to_green  sg_total  scoring_avg  \n",
       "0       0.416            1.873     2.289       68.653  \n",
       "1      -0.136            0.739     0.603       70.669  \n",
       "2      -0.062            0.120     0.059       70.966  \n",
       "3       0.528            0.699     1.227       70.879  \n",
       "4       0.407           -1.317    -0.910       72.117  "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import new csv file that contains data on missing golfers\n",
    "missing = pd.read_csv('csv_files/masters_results - missing.csv')\n",
    "\n",
    "print(missing.shape)\n",
    "missing.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3036, 18)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>full_name</th>\n",
       "      <th>driving_distance</th>\n",
       "      <th>driving_accuracy</th>\n",
       "      <th>greens_in_regulation</th>\n",
       "      <th>proximity</th>\n",
       "      <th>scrambling_rough</th>\n",
       "      <th>scrambling_sand</th>\n",
       "      <th>putting_conversion</th>\n",
       "      <th>putting_rating</th>\n",
       "      <th>sg_off_tee</th>\n",
       "      <th>sg_approach</th>\n",
       "      <th>sg_scrambling</th>\n",
       "      <th>sg_putting</th>\n",
       "      <th>sg_tee_to_green</th>\n",
       "      <th>sg_total</th>\n",
       "      <th>str_diff_to_field</th>\n",
       "      <th>scoring_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>aaron_baddeley</td>\n",
       "      <td>288.0</td>\n",
       "      <td>0.5308</td>\n",
       "      <td>0.5817</td>\n",
       "      <td>39.333333</td>\n",
       "      <td>0.5769</td>\n",
       "      <td>0.5351</td>\n",
       "      <td>0.3015</td>\n",
       "      <td>1.576</td>\n",
       "      <td>-0.530</td>\n",
       "      <td>-0.679</td>\n",
       "      <td>0.201</td>\n",
       "      <td>0.579</td>\n",
       "      <td>-1.008</td>\n",
       "      <td>-0.429</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>71.614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>adam_scott</td>\n",
       "      <td>295.4</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>0.5301</td>\n",
       "      <td>0.6170</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>1.611</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.603</td>\n",
       "      <td>1.427</td>\n",
       "      <td>1.30</td>\n",
       "      <td>70.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>alex_cejka</td>\n",
       "      <td>285.8</td>\n",
       "      <td>0.6421</td>\n",
       "      <td>0.6381</td>\n",
       "      <td>36.083333</td>\n",
       "      <td>0.5108</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.2877</td>\n",
       "      <td>1.625</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.255</td>\n",
       "      <td>0.020</td>\n",
       "      <td>-0.006</td>\n",
       "      <td>0.394</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.27</td>\n",
       "      <td>71.153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>andre_stolz</td>\n",
       "      <td>297.9</td>\n",
       "      <td>0.5897</td>\n",
       "      <td>0.6300</td>\n",
       "      <td>36.416667</td>\n",
       "      <td>0.4632</td>\n",
       "      <td>0.5244</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>1.628</td>\n",
       "      <td>-0.333</td>\n",
       "      <td>-0.532</td>\n",
       "      <td>-0.137</td>\n",
       "      <td>-0.246</td>\n",
       "      <td>-1.002</td>\n",
       "      <td>-1.247</td>\n",
       "      <td>-0.99</td>\n",
       "      <td>72.341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>arjun_atwal</td>\n",
       "      <td>289.4</td>\n",
       "      <td>0.6048</td>\n",
       "      <td>0.6252</td>\n",
       "      <td>35.916667</td>\n",
       "      <td>0.5979</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2980</td>\n",
       "      <td>1.606</td>\n",
       "      <td>0.013</td>\n",
       "      <td>-0.097</td>\n",
       "      <td>-0.116</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.200</td>\n",
       "      <td>-0.234</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>71.688</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   season       full_name  driving_distance  driving_accuracy  \\\n",
       "0    2004  aaron_baddeley             288.0            0.5308   \n",
       "1    2004      adam_scott             295.4            0.5765   \n",
       "2    2004      alex_cejka             285.8            0.6421   \n",
       "3    2004     andre_stolz             297.9            0.5897   \n",
       "4    2004     arjun_atwal             289.4            0.6048   \n",
       "\n",
       "   greens_in_regulation  proximity  scrambling_rough  scrambling_sand  \\\n",
       "0                0.5817  39.333333            0.5769           0.5351   \n",
       "1                0.6560  35.333333            0.5301           0.6170   \n",
       "2                0.6381  36.083333            0.5108           0.5765   \n",
       "3                0.6300  36.416667            0.4632           0.5244   \n",
       "4                0.6252  35.916667            0.5979           0.4107   \n",
       "\n",
       "   putting_conversion  putting_rating  sg_off_tee  sg_approach  sg_scrambling  \\\n",
       "0              0.3015           1.576      -0.530       -0.679          0.201   \n",
       "1              0.3290           1.611       0.180        0.571         -0.147   \n",
       "2              0.2877           1.625       0.119        0.255          0.020   \n",
       "3              0.2838           1.628      -0.333       -0.532         -0.137   \n",
       "4              0.2980           1.606       0.013       -0.097         -0.116   \n",
       "\n",
       "   sg_putting  sg_tee_to_green  sg_total  str_diff_to_field  scoring_avg  \n",
       "0       0.579           -1.008    -0.429              -0.44       71.614  \n",
       "1       0.824            0.603     1.427               1.30       70.096  \n",
       "2      -0.006            0.394     0.388               0.27       71.153  \n",
       "3      -0.246           -1.002    -1.247              -0.99       72.341  \n",
       "4      -0.034           -0.200    -0.234              -0.25       71.688  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reload and examine new dataframe\n",
    "df = pd.read_csv('csv_files/golfer_data.csv')\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert proximity to feet floats and str_diff_to_field to stroke floats\n",
    "df['proximity'] = df['proximity'].apply(lambda x: convert_to_feet(x))\n",
    "\n",
    "# Convert percentage features to decimals\n",
    "df['driving_accuracy'] = df['driving_accuracy']/100\n",
    "df['greens_in_regulation'] = df['greens_in_regulation']/100\n",
    "df['scrambling_rough'] = df['scrambling_rough']/100\n",
    "df['scrambling_sand'] = df['scrambling_sand']/100\n",
    "df['putting_conversion'] = df['putting_conversion']/100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Incorporate Historical Tournament Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1469, 6)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>masters_year</th>\n",
       "      <th>full_name</th>\n",
       "      <th>total_score</th>\n",
       "      <th>made_cut</th>\n",
       "      <th>top_10</th>\n",
       "      <th>champion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2005</td>\n",
       "      <td>adam_scott</td>\n",
       "      <td>294</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>2005</td>\n",
       "      <td>austin_eaton_iii</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>2005</td>\n",
       "      <td>ben_crenshaw</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2005</td>\n",
       "      <td>ben_curtis</td>\n",
       "      <td>315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2005</td>\n",
       "      <td>bernhard_langer</td>\n",
       "      <td>289</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    masters_year         full_name  total_score  made_cut  top_10  champion\n",
       "32          2005        adam_scott          294         1       0         0\n",
       "51          2005  austin_eaton_iii          315         0       0         0\n",
       "52          2005      ben_crenshaw          315         0       0         0\n",
       "53          2005        ben_curtis          315         0       0         0\n",
       "19          2005   bernhard_langer          289         1       0         0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Masters Results data and format each golfer to match our data's format\n",
    "masters_results = pd.read_csv('csv_files/masters_results - data.csv')\n",
    "masters_results['full_name'] = masters_results['full_name'].apply(lambda x: format_golfer(x))\n",
    "masters_results = masters_results.sort_values(by=['masters_year', 'full_name'])\n",
    "\n",
    "print(masters_results.shape)\n",
    "masters_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(922, 22)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>full_name</th>\n",
       "      <th>champion</th>\n",
       "      <th>top_10</th>\n",
       "      <th>made_cut</th>\n",
       "      <th>total_score</th>\n",
       "      <th>driving_distance</th>\n",
       "      <th>driving_accuracy</th>\n",
       "      <th>greens_in_regulation</th>\n",
       "      <th>proximity</th>\n",
       "      <th>...</th>\n",
       "      <th>putting_conversion</th>\n",
       "      <th>putting_rating</th>\n",
       "      <th>sg_off_tee</th>\n",
       "      <th>sg_approach</th>\n",
       "      <th>sg_scrambling</th>\n",
       "      <th>sg_putting</th>\n",
       "      <th>sg_tee_to_green</th>\n",
       "      <th>sg_total</th>\n",
       "      <th>str_diff_to_field</th>\n",
       "      <th>scoring_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2004</td>\n",
       "      <td>adam_scott</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>294</td>\n",
       "      <td>295.4</td>\n",
       "      <td>0.5765</td>\n",
       "      <td>0.6560</td>\n",
       "      <td>35.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3290</td>\n",
       "      <td>1.611</td>\n",
       "      <td>0.180</td>\n",
       "      <td>0.571</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>0.824</td>\n",
       "      <td>0.603</td>\n",
       "      <td>1.427</td>\n",
       "      <td>1.30</td>\n",
       "      <td>70.096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004</td>\n",
       "      <td>ben_curtis</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>282.1</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>0.6335</td>\n",
       "      <td>37.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2513</td>\n",
       "      <td>1.620</td>\n",
       "      <td>0.171</td>\n",
       "      <td>0.274</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-0.174</td>\n",
       "      <td>0.669</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.09</td>\n",
       "      <td>71.578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2004</td>\n",
       "      <td>bernhard_langer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>289</td>\n",
       "      <td>282.2</td>\n",
       "      <td>0.6257</td>\n",
       "      <td>0.6525</td>\n",
       "      <td>34.416667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2768</td>\n",
       "      <td>1.608</td>\n",
       "      <td>0.029</td>\n",
       "      <td>0.616</td>\n",
       "      <td>0.055</td>\n",
       "      <td>-0.229</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.39</td>\n",
       "      <td>71.246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2004</td>\n",
       "      <td>bo_van_pelt</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>294.4</td>\n",
       "      <td>0.6515</td>\n",
       "      <td>0.6768</td>\n",
       "      <td>36.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.3136</td>\n",
       "      <td>1.623</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.094</td>\n",
       "      <td>0.346</td>\n",
       "      <td>0.800</td>\n",
       "      <td>1.146</td>\n",
       "      <td>0.99</td>\n",
       "      <td>70.245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2004</td>\n",
       "      <td>carlos_franco</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315</td>\n",
       "      <td>290.6</td>\n",
       "      <td>0.5933</td>\n",
       "      <td>0.6846</td>\n",
       "      <td>36.083333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.2838</td>\n",
       "      <td>1.637</td>\n",
       "      <td>0.130</td>\n",
       "      <td>0.413</td>\n",
       "      <td>0.236</td>\n",
       "      <td>-0.134</td>\n",
       "      <td>0.779</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.61</td>\n",
       "      <td>70.768</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   season        full_name  champion  top_10  made_cut  total_score  \\\n",
       "0    2004       adam_scott         0       0         1          294   \n",
       "1    2004       ben_curtis         0       0         0          315   \n",
       "2    2004  bernhard_langer         0       0         1          289   \n",
       "3    2004      bo_van_pelt         0       0         0          315   \n",
       "4    2004    carlos_franco         0       0         0          315   \n",
       "\n",
       "   driving_distance  driving_accuracy  greens_in_regulation  proximity  ...  \\\n",
       "0             295.4            0.5765                0.6560  35.333333  ...   \n",
       "1             282.1            0.6434                0.6335  37.333333  ...   \n",
       "2             282.2            0.6257                0.6525  34.416667  ...   \n",
       "3             294.4            0.6515                0.6768  36.333333  ...   \n",
       "4             290.6            0.5933                0.6846  36.083333  ...   \n",
       "\n",
       "   putting_conversion  putting_rating  sg_off_tee  sg_approach  sg_scrambling  \\\n",
       "0              0.3290           1.611       0.180        0.571         -0.147   \n",
       "1              0.2513           1.620       0.171        0.274          0.223   \n",
       "2              0.2768           1.608       0.029        0.616          0.055   \n",
       "3              0.3136           1.623       0.512        0.194          0.094   \n",
       "4              0.2838           1.637       0.130        0.413          0.236   \n",
       "\n",
       "   sg_putting  sg_tee_to_green  sg_total  str_diff_to_field  scoring_avg  \n",
       "0       0.824            0.603     1.427               1.30       70.096  \n",
       "1      -0.174            0.669     0.494               0.09       71.578  \n",
       "2      -0.229            0.700     0.471               0.39       71.246  \n",
       "3       0.346            0.800     1.146               0.99       70.245  \n",
       "4      -0.134            0.779     0.645               0.61       70.768  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge dataframes together on name\n",
    "df = pd.merge(df, masters_results, how='left', on='full_name')\n",
    "\n",
    "# Drop Nans\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Only consider rows where golfer participated the following masters\n",
    "df = df[df['masters_year']-df['season'] == 1]\n",
    "\n",
    "# Drop Masters year and reset Index\n",
    "df.drop('masters_year', axis=1, inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Change made_cut and top_10 to integers\n",
    "df['made_cut'] = df['made_cut'].astype(int)\n",
    "df['top_10'] = df['top_10'].astype(int)\n",
    "df['champion'] = df['champion'].astype(int)\n",
    "df['total_score'] = df['total_score'].astype(int)\n",
    "\n",
    "# Reorder columns and examine new dataframe\n",
    "cols = ['season', 'full_name', 'champion', 'top_10', 'made_cut', 'total_score',\n",
    "        'driving_distance', 'driving_accuracy', 'greens_in_regulation', 'proximity',\n",
    "        'scrambling_rough', 'scrambling_sand', 'putting_conversion', 'putting_rating',\n",
    "        'sg_off_tee', 'sg_approach', 'sg_scrambling', 'sg_putting', 'sg_tee_to_green',\n",
    "        'sg_total', 'str_diff_to_field', 'scoring_avg']\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'full_name', 'champion', 'top_10', 'made_cut', 'total_score',\n",
       "       'driving_distance', 'driving_accuracy', 'greens_in_regulation',\n",
       "       'proximity', 'scrambling_rough', 'scrambling_sand',\n",
       "       'putting_conversion', 'putting_rating', 'sg_off_tee', 'sg_approach',\n",
       "       'sg_scrambling', 'sg_putting', 'sg_tee_to_green', 'sg_total',\n",
       "       'str_diff_to_field', 'scoring_avg'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Par or Better Distance\n",
    "Generate a circle where the radius equals a golfer's maximum distance from the hole in which the golfer will make a par or better from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['on_the_green_area'] = df['proximity']**2 * np.pi\n",
    "df['birdie_or_better_area'] = df['on_the_green_area']*df['putting_conversion']\n",
    "df['birdie_or_better_distance'] = np.sqrt(df['birdie_or_better_area']/np.pi)\n",
    "df['birdie_or_worse_distance'] = df['proximity']-df['birdie_or_better_distance']\n",
    "df.drop(['proximity', 'putting_conversion', 'on_the_green_area', 'birdie_or_better_area'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist_scores = pd.DataFrame(df[df['season'] != 2019].groupby('full_name').total_score.mean())\n",
    "hist_scores.reset_index(drop=False, inplace=True)\n",
    "hist_scores['avg_score'] = hist_scores['total_score'].astype(int)\n",
    "hist_scores.drop('total_score', axis=1, inplace=True)\n",
    "\n",
    "df = pd.merge(df, hist_scores, how='inner', on='full_name')\n",
    "\n",
    "cols = ['season', 'full_name', 'champion', 'top_10', 'made_cut', 'total_score',\n",
    "        'avg_score', 'driving_distance', 'driving_accuracy', 'greens_in_regulation',\n",
    "        'scrambling', 'putting_rating', 'birdie_or_better_distance','birdie_or_worse_distance', ]\n",
    "\n",
    "df = df[cols]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df['full_name'] == 'zach_johnson']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prior Tournament Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group data by golfer then season in order to lag total score column\n",
    "df = df.groupby(['full_name', 'season'])['driving_distance',\n",
    "                                         'driving_accuracy',\n",
    "                                         'greens_in_regulation',\n",
    "                                         'par_or_better_distance',\n",
    "                                         'par_or_worse_distance',\n",
    "                                         'scrambling',\n",
    "                                         'putting_rating',\n",
    "                                         'total_score',\n",
    "                                         'made_cut',\n",
    "                                         'top_10',\n",
    "                                         'champion'].mean()\n",
    "\n",
    "# Save grouped data locally by ovewriting current csv\n",
    "df.to_csv('csv_files/noSG/golfer_data.csv')\n",
    "\n",
    "# Reload and examine new dataframe\n",
    "df = pd.read_csv('csv_files/noSG/golfer_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a list of unique golfers\n",
    "golfers = df['full_name'].unique().tolist()\n",
    "\n",
    "# Create a list of dictionaries to house each golfers score at the Masters for every tournament he played in\n",
    "names_and_scores = []\n",
    "for golfer in golfers:\n",
    "    name_and_scores = {}\n",
    "    name_and_scores['golfer'] = golfer\n",
    "    scores = []\n",
    "    for i in range(df.shape[0]):\n",
    "        if golfer == df['full_name'].iloc[i]:\n",
    "            scores.append(df['total_score'].iloc[i])\n",
    "        else:\n",
    "            continue\n",
    "    name_and_scores['scores'] = scores\n",
    "    names_and_scores.append(name_and_scores)\n",
    "\n",
    "# Loop through list of dictionaries and create a lagged score list for each golfer\n",
    "for golfer in names_and_scores:\n",
    "    scores_lagged = []\n",
    "    for i in range(len(golfer['scores'])):\n",
    "        score_lagged = golfer['scores'][i-1]\n",
    "        scores_lagged.append(score_lagged)\n",
    "        scores_lagged[0] = 315\n",
    "    golfer['scores_lagged'] = scores_lagged\n",
    "\n",
    "# Join all of the sepearate lists together\n",
    "lagged_scores = []\n",
    "for golfer in names_and_scores:\n",
    "    lagged_scores.extend(golfer['scores_lagged'])\n",
    "    \n",
    "# Add the lagged scores to our dataframe\n",
    "df['prior_score'] = lagged_scores\n",
    "\n",
    "# Convert column to int\n",
    "df['prior_score'] = df['prior_score'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Masters Experience\n",
    "Create another column that quantifies how many times a golfer has played at the Masters at that point in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['experience'] = 0\n",
    "golfers = df['full_name'].unique().tolist()\n",
    "\n",
    "for golfer in golfers:\n",
    "    count = 0\n",
    "    for i in range(df.shape[0]):\n",
    "        if df['full_name'].iloc[i] == golfer:\n",
    "            count += 1\n",
    "            df['experience'].iloc[i] = count\n",
    "        else:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Field Average Score\n",
    "Create a column that is the average score of the field that year for each golfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get each year's Masters Tournament average score for the field\n",
    "hist_scores = pd.DataFrame(df.groupby('season')['total_score'].agg('mean'))\n",
    "hist_scores.reset_index(drop=False, inplace=True)\n",
    "hist_scores['field_avg_score'] = hist_scores['total_score'].astype(int)\n",
    "hist_scores.drop('total_score', axis=1, inplace=True)\n",
    "\n",
    "# Merge with our dataframe\n",
    "df = pd.merge(df, hist_scores, how='inner', on='season')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Strokes Gained Over Field\n",
    "Create a new column that calculates how much better (or worse) the golfer did than the field average that year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column\n",
    "df['sg_over_field'] = df['field_avg_score']-df['total_score']\n",
    "\n",
    "# Reorganize columns and examine dataframe\n",
    "cols = ['full_name', 'season', 'experience', 'champion', 'top_10',\n",
    "        'made_cut', 'field_avg_score', 'total_score',\n",
    "        'sg_over_field', 'prior_score', 'driving_distance',\n",
    "        'driving_accuracy', 'greens_in_regulation',\n",
    "        'par_or_better_distance', 'par_or_worse_distance',\n",
    "        'scrambling', 'putting_rating']\n",
    "df = df[cols]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create holdout set of 2019 data. Holdout set will be used for predicting 2020 Masters results\n",
    "holdout = df[df['season'] == 2019]\n",
    "df = df[df['season'] != 2019]\n",
    "\n",
    "# Examine holdout and dataframe\n",
    "print(f\"Holdout Set: {holdout.shape}\")\n",
    "print(f\"Validation Set: {df.shape}\")\n",
    "\n",
    "# Overwrite grouped data and save both the holdout set and grouped dataframe locally\n",
    "holdout.to_csv('csv_files/noSG/holdout_data.csv')\n",
    "df.to_csv('csv_files/noSG/golfer_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv_files/noSG/final_golfer_data.csv', index_col=0)\n",
    "\n",
    "print(df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10 = df[df['top_10'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['season', 'total_score', 'made_cut', 'top_10', 'champion'],axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top10.drop(['season', 'total_score', 'made_cut', 'top_10', 'champion'],axis=1).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cutlines\n",
    "cut_lines = pd.read_csv('csv_files/masters_results - cutline.csv')\n",
    "\n",
    "print(cut_lines.shape)\n",
    "cut_lines.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "target_variable = 'made_cut'\n",
    "title = target_variable.replace('_', ' ').title()\n",
    "fig = plt.figure(figsize=(13,5));\n",
    "\n",
    "# Percent of Golfers Cut\n",
    "height = df.groupby(target_variable).season.count().tolist()\n",
    "missed_cut = height[0]\n",
    "made_cut = height[1]\n",
    "ax1 = fig.add_subplot(121);\n",
    "ax1.bar(\n",
    "    x=0, \n",
    "    height=made_cut,\n",
    "    ec='darkgreen',\n",
    "    fc='darkgreen',\n",
    "    label=f'Made Cut: {made_cut/(made_cut+missed_cut) : 0.1%}'\n",
    ");\n",
    "ax1.bar(\n",
    "    x=1, \n",
    "    height=missed_cut,\n",
    "    ec='darkgreen',\n",
    "    fc='yellow',\n",
    "    label=f'Missed Cut: {missed_cut/(made_cut+missed_cut) : 0.1%}'\n",
    ");\n",
    "ax1.set_title(\"Percent of Golfers Cut\", {'fontsize' : 16});\n",
    "ax1.set_ylabel('Number of Golfers', {'fontsize' : 14});\n",
    "ax1.set_xticks(ticks=[0,1]);\n",
    "ax1.set_xticklabels(labels=['Made the Cut', 'Missed the Cut'], fontdict={'fontsize' : 14});\n",
    "ax1.legend(loc='upper right', fontsize='large');\n",
    "\n",
    "# Cutline overtime\n",
    "avg_cutline = int(cut_lines['relative_to_par'].mean())\n",
    "ax2 = fig.add_subplot(122);\n",
    "\n",
    "cut_lines.groupby('season').relative_to_par.mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax2,\n",
    "    fontsize=12,\n",
    "    marker='o',\n",
    "    mec='darkgreen',\n",
    "    mfc='yellow',\n",
    "    linestyle='--',\n",
    "    linewidth=1.0,\n",
    "    color='red',\n",
    "    label=f'Avg. Cut Line: +{avg_cutline}'\n",
    ");\n",
    "ax2.set_title(\"Tournament Cut Line by Year\", {'fontsize' : 16});\n",
    "ax2.set_ylabel('Score Relative To Par', {'fontsize' : 14});\n",
    "ax2.set_yticks(range(0, 11));\n",
    "ax2.set_yticklabels(\n",
    "    ('E', '+1', '+2', '+3', '+4',\n",
    "     '+5', '+6', '+7', '+8', '+9', '+10')\n",
    ");\n",
    "ax2.legend(loc='upper right', fontsize='large');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_variable = 'top_10'\n",
    "title = target_variable.replace('_', ' ').title()\n",
    "fig = plt.figure(figsize=(13,5));\n",
    "\n",
    "# Percent of Golfers Inside Top 10\n",
    "height = df.groupby(target_variable).season.count().tolist()\n",
    "outside_top10 = height[0]\n",
    "inside_top10 = height[1]\n",
    "ax1 = fig.add_subplot(121);\n",
    "ax1.bar(\n",
    "    x=0, \n",
    "    height=inside_top10,\n",
    "    ec='darkgreen',\n",
    "    fc='darkgreen',\n",
    "    label=f'Inside: {inside_top10/(inside_top10+outside_top10) : 0.1%}'\n",
    ");\n",
    "ax1.bar(\n",
    "    x=1, \n",
    "    height=missed_cut,\n",
    "    ec='darkgreen',\n",
    "    fc='yellow',\n",
    "    label=f'Outside: {outside_top10/(inside_top10+outside_top10) : 0.1%}'\n",
    ");\n",
    "ax1.set_title(\"Top 10 Summary\", {'fontsize' : 16});\n",
    "ax1.set_ylabel('Number of Golfers', {'fontsize' : 14});\n",
    "ax1.set_xticks(ticks=[0,1]);\n",
    "ax1.set_xticklabels(labels=['Inside', 'Outside'], fontdict={'fontsize' : 14});\n",
    "ax1.legend(loc='upper left', fontsize='large');\n",
    "\n",
    "# Top 10 overtime\n",
    "top_10 = pd.DataFrame(df[df['top_10'] == 1].groupby('season').total_score.max())\n",
    "top_10.reset_index(drop=False, inplace=True)\n",
    "top_10['season'] = top_10['season']+1\n",
    "top_10['relative_to_par'] = top_10['total_score']-(72*4)\n",
    "avg_top10 = int(top_10['relative_to_par'].mean())\n",
    "ax2 = fig.add_subplot(122);\n",
    "\n",
    "top_10.groupby('season').relative_to_par.mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax2,\n",
    "    fontsize=12,\n",
    "    marker='o',\n",
    "    mec='darkgreen',\n",
    "    mfc='yellow',\n",
    "    linestyle='--',\n",
    "    linewidth=1.0,\n",
    "    color='red',\n",
    "    label=f'Avg. Top 10 Score: {avg_top10}'\n",
    ");\n",
    "ax2.set_title(\"Top 10 by Year\", {'fontsize' : 16});\n",
    "ax2.set_ylabel('Score Relative To Par', {'fontsize' : 14});\n",
    "ax2.legend(loc='upper right', fontsize='large');\n",
    "ax2.set_yticks(range(-11, 9));\n",
    "ax2.set_yticklabels(\n",
    "    ('-11', '-10', '-9', '-8',\n",
    "     '-7', '-6', '-5', '-4',\n",
    "     '-3', '-2', '-1', 'E',\n",
    "     '+1', '+2', '+3', '+4',\n",
    "     '+5', '+6', '+7', '+8')\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = df.drop(['season', 'full_name', 'field_avg_score', 'total_score', 'sg_over_field'], axis=1)\n",
    "cols=['champion', 'top_10', 'made_cut', 'prior_score', 'experience',\n",
    "       'driving_distance', 'driving_accuracy', 'greens_in_regulation',\n",
    "       'par_or_better_distance', 'par_or_worse_distance', 'scrambling',\n",
    "       'putting_rating']\n",
    "df_corr = df_corr[cols]\n",
    "\n",
    "fig = plt.figure(figsize=(11,11))\n",
    "\n",
    "# Create mask\n",
    "mask = np.zeros_like(df_corr.corr(), dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "# Create color scheme\n",
    "cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "ax1 = fig.add_subplot(111)\n",
    "sns.heatmap(df_corr.corr(),\n",
    "            mask=mask, \n",
    "            cmap=cmap,\n",
    "            center=0,\n",
    "            vmin=-1,\n",
    "            vmax=1,\n",
    "            square=True,\n",
    "            linewidths=0.5,\n",
    "            cbar_kws={'shrink': 0.5},\n",
    "            ax=ax1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations by Feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Strokes Gained Per Round"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=figsize);\n",
    "ax = fig.add_subplot(111);\n",
    "\n",
    "sns.boxplot(\n",
    "    x=df['experience'],\n",
    "    y=df['sg_over_field']\n",
    ");\n",
    "ax.axhline(0, color='black', linestyle='--');\n",
    "ax.set_ylabel('Strokes Gained Per Round', fontsize=12);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prior Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only consider times after 2002 since no one has data prior\n",
    "df_no_2002 = df[df['season'] != 2002]\n",
    "\n",
    "# Define sub-dataframes for visualizations\n",
    "made_cut = df_no_2002[df_no_2002['made_cut'] == 1]\n",
    "missed_cut = df_no_2002[df_no_2002['made_cut'] == 0]\n",
    "inside_top10 = df_no_2002[df_no_2002['top_10'] == 1]\n",
    "outside_top10 = df_no_2002[df_no_2002['top_10'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define universal Variables\n",
    "feature = 'prior_score'\n",
    "mean1_made = round(made_cut[feature].mean(), 1)\n",
    "mean1_missed = round(missed_cut[feature].mean(), 1)\n",
    "mean2_in = round(inside_top10[feature].mean(), 1)\n",
    "mean2_out = round(outside_top10[feature].mean(), 1)\n",
    "fig = plt.figure(figsize=figsize);\n",
    "fig.subplots_adjust(hspace=hspace);\n",
    "xmin = 265\n",
    "xmax = 320\n",
    "ymin = 285\n",
    "ymax = 320\n",
    "missed_cut_min = df_no_2002[df_no_2002['made_cut']==0][feature].min()\n",
    "out_t10_min = df_no_2002[df_no_2002['top_10']==0][feature].min()\n",
    "\n",
    "# Made Cut - Dist Plot\n",
    "ax1 = fig.add_subplot(231);\n",
    "sns.distplot(\n",
    "    made_cut[feature], \n",
    "    bins='auto',\n",
    "    color='blue',\n",
    "    ax=ax1\n",
    ");\n",
    "sns.distplot(\n",
    "    missed_cut[feature],\n",
    "    bins='auto',\n",
    "    color='red',\n",
    "    ax=ax1\n",
    ");\n",
    "ax1.axvline(mean1_made, linestyle='--', color='blue', label=f'Made Cut Avg: {mean1_made}');\n",
    "ax1.axvline(mean1_missed, linestyle='--', color='red', label=f'Missed Cut Avg: {mean1_missed}');\n",
    "ax1.set_title('Distribution Plot - Made Cut');\n",
    "ax1.set_xlim(xmin, xmax);\n",
    "ax1.legend();\n",
    "\n",
    "# Made Cut - Scatter Plot\n",
    "ax2 = fig.add_subplot(232);\n",
    "sns.scatterplot(\n",
    "    x=df_no_2002[feature],\n",
    "    y=df_no_2002['made_cut'],\n",
    "    hue=df_no_2002['made_cut'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax2\n",
    ");\n",
    "ax2.axvline(missed_cut_min, linestyle = '--', color ='red', label=f'Missed Cut Min: {missed_cut_min}');\n",
    "ax2.set_title('Scatter Plot - Made Cut');\n",
    "ax2.set_xlim(xmin, xmax);\n",
    "ax2.legend(loc='center');\n",
    "\n",
    "# Made Cut - Mean Overtime\n",
    "ax3 = fig.add_subplot(233);\n",
    "made_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Made Cut Avg.'\n",
    ");\n",
    "missed_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Missed Cut Avg.'\n",
    ");\n",
    "ax3.set_title('Average Overtime - Made Cut', {'fontsize' : 12});\n",
    "ax3.set_ylim(ymin, ymax);\n",
    "ax3.legend();\n",
    "\n",
    "# Top 10 - Dist Plot\n",
    "ax4 = fig.add_subplot(234);\n",
    "sns.distplot(\n",
    "    inside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='blue',\n",
    "    ax=ax4\n",
    ");\n",
    "sns.distplot(\n",
    "    outside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='red',\n",
    "    ax=ax4\n",
    ");\n",
    "ax4.axvline(mean2_in, linestyle='--', color='blue', label=f'Inside Avg: {mean2_in}');\n",
    "ax4.axvline(mean2_out, linestyle='--', color='red', label=f'Outside Avg: {mean2_out}');\n",
    "ax4.set_title('Distribution Plot - Top 10');\n",
    "ax4.set_xlim(xmin, xmax);\n",
    "ax4.legend();\n",
    "\n",
    "# Top 10 - Scatter Plot\n",
    "ax5 = fig.add_subplot(235);\n",
    "sns.scatterplot(\n",
    "    x=df_no_2002[feature],\n",
    "    y=df_no_2002['top_10'],\n",
    "    hue=df_no_2002['top_10'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax5\n",
    ");\n",
    "ax5.axvline(out_t10_min, linestyle = '--', color ='red', label=f'Outside Top 10 Min: {out_t10_min}');\n",
    "ax5.set_title('Scatter Plot - Top 10');\n",
    "ax5.set_xlim(xmin, xmax);\n",
    "ax5.legend(loc='center');\n",
    "\n",
    "# Top 10 - Mean Overtime\n",
    "ax6 = fig.add_subplot(236);\n",
    "inside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Inside Top 10 Avg.'\n",
    ");\n",
    "outside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Outside Top 10 Avg.' \n",
    ");\n",
    "ax6.set_title('Average Overtime - Top 10', {'fontsize' : 12});\n",
    "ax6.set_ylim(ymin, ymax);\n",
    "ax6.legend();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driving Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Re-define sub-dataframes for correct time period\n",
    "made_cut = df[df['made_cut'] == 1]\n",
    "missed_cut = df[df['made_cut'] == 0]\n",
    "inside_top10 = df[df['top_10'] == 1]\n",
    "outside_top10 = df[df['top_10'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define universal Variables\n",
    "feature = 'driving_distance'\n",
    "mean1_made = round(made_cut[feature].mean(), 1)\n",
    "mean1_missed = round(missed_cut[feature].mean(), 1)\n",
    "mean2_in = round(inside_top10[feature].mean(), 1)\n",
    "mean2_out = round(outside_top10[feature].mean(), 1)\n",
    "fig = plt.figure(figsize=figsize);\n",
    "fig.subplots_adjust(hspace=hspace);\n",
    "xmin = 260\n",
    "xmax = 330\n",
    "ymin = 270\n",
    "ymax = 310\n",
    "made_cut_min = df[df['made_cut']==1][feature].min()\n",
    "missed_cut_max = df[df['made_cut']==0][feature].max()\n",
    "in_t10_min = df[df['top_10']==1][feature].min()\n",
    "out_t10_max = df[df['top_10']==0][feature].max()\n",
    "\n",
    "# Made Cut - Dist Plot\n",
    "ax1 = fig.add_subplot(231);\n",
    "sns.distplot(\n",
    "    made_cut[feature], \n",
    "    bins='auto', \n",
    "    color='blue', \n",
    "    ax=ax1\n",
    ");\n",
    "sns.distplot(\n",
    "    missed_cut[feature], \n",
    "    bins='auto', \n",
    "    color='red', \n",
    "    ax=ax1\n",
    ");\n",
    "ax1.axvline(mean1_made, linestyle='--', color='blue', label=f'Made Cut Avg: {mean1_made}');\n",
    "ax1.axvline(mean1_missed, linestyle='--', color='red', label=f'Missed Cut Avg: {mean1_missed}');\n",
    "ax1.set_title('Distribution Plot - Made Cut');\n",
    "ax1.set_xlim(xmin, xmax);\n",
    "ax1.legend(loc='upper right');\n",
    "\n",
    "# Made Cut - Scatter Plot\n",
    "ax2 = fig.add_subplot(232);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['made_cut'],\n",
    "    hue=df['made_cut'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax2\n",
    ");\n",
    "ax2.axvline(made_cut_min, linestyle = '--', color ='blue', label=f'Made Cut Min: {made_cut_min}');\n",
    "ax2.axvline(missed_cut_max, linestyle = '--', color ='red', label=f'Missed Cut Max: {missed_cut_max}');\n",
    "ax2.set_title('Scatter Plot - Made Cut');\n",
    "ax2.set_xlim(xmin, xmax);\n",
    "ax2.legend(loc='center');\n",
    "\n",
    "# Made Cut - Mean Overtime\n",
    "ax3 = fig.add_subplot(233);\n",
    "made_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Made Cut Avg.'\n",
    ");\n",
    "missed_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Missed Cut Avg.'\n",
    ");\n",
    "ax3.set_title('Average Overtime - Made Cut', {'fontsize' : 12});\n",
    "ax3.set_ylim(ymin, ymax);\n",
    "ax3.legend(loc='upper left');\n",
    "\n",
    "# Top 10 - Dist Plot\n",
    "ax4 = fig.add_subplot(234);\n",
    "sns.distplot(\n",
    "    inside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='blue',\n",
    "    ax=ax4\n",
    ");\n",
    "sns.distplot(\n",
    "    outside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='red',\n",
    "    ax=ax4\n",
    ");\n",
    "ax4.axvline(mean2_in, linestyle='--', color='blue', label=f'Inside Avg: {mean2_in}');\n",
    "ax4.axvline(mean2_out, linestyle='--', color='red', label=f'Outside Avg: {mean2_out}');\n",
    "ax4.set_title('Distribution Plot - Top 10');\n",
    "ax4.set_xlim(xmin, xmax);\n",
    "ax4.legend(loc='upper right');\n",
    "\n",
    "# Top 10 - Scatter Plot\n",
    "ax5 = fig.add_subplot(235);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['top_10'],\n",
    "    hue=df['top_10'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax5\n",
    ");\n",
    "ax5.axvline(in_t10_min, linestyle = '--', color ='blue', label=f'Inside Top 10 Min: {in_t10_min}');\n",
    "ax5.axvline(out_t10_max, linestyle = '--', color ='red', label=f'Outside Top 10 Max: {out_t10_max}');\n",
    "ax5.set_title('Scatter Plot - Top 10');\n",
    "ax5.set_xlim(xmin, xmax);\n",
    "ax5.legend(loc='center');\n",
    "\n",
    "# Top 10 - Mean Overtime\n",
    "ax6 = fig.add_subplot(236);\n",
    "inside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Inside Top 10 Avg.'\n",
    ");\n",
    "outside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Outside Top 10 Avg.'\n",
    ");\n",
    "ax6.set_title('Average Overtime - Top 10', {'fontsize' : 12});\n",
    "ax6.set_ylim(ymin, ymax);\n",
    "ax6.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Driving Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'driving_accuracy'\n",
    "mean1_made = made_cut[feature].mean()\n",
    "mean1_missed = missed_cut[feature].mean()\n",
    "mean2_in = inside_top10[feature].mean()\n",
    "mean2_out = outside_top10[feature].mean()\n",
    "fig = plt.figure(figsize=figsize);\n",
    "fig.subplots_adjust(hspace=hspace);\n",
    "xmin = 0.4\n",
    "xmax = 0.9\n",
    "ymin = 0.55\n",
    "ymax = 0.7\n",
    "made_cut_min = df[df['made_cut']==1][feature].min()\n",
    "missed_cut_max = df[df['made_cut']==0][feature].max()\n",
    "in_t10_min = df[df['top_10']==1][feature].min()\n",
    "out_t10_max = df[df['top_10']==0][feature].max()\n",
    "\n",
    "# Made Cut - Dist Plot\n",
    "ax1 = fig.add_subplot(231);\n",
    "sns.distplot(\n",
    "    made_cut[feature], \n",
    "    bins='auto', \n",
    "    color='blue', \n",
    "    ax=ax1\n",
    ");\n",
    "sns.distplot(\n",
    "    missed_cut[feature], \n",
    "    bins='auto', \n",
    "    color='red', \n",
    "    ax=ax1\n",
    ");\n",
    "ax1.axvline(mean1_made, linestyle='--', color='blue', label=f'Made Cut Avg: {mean1_made : 0.2%}');\n",
    "ax1.axvline(mean1_missed, linestyle='--', color='red', label=f'Missed Cut Avg: {mean1_missed : 0.2%}');\n",
    "ax1.set_title('Distribution Plot - Made Cut');\n",
    "ax1.set_xlim(xmin, xmax);\n",
    "ax1.legend(loc='upper right');\n",
    "\n",
    "# Made Cut - Scatter Plot\n",
    "ax2 = fig.add_subplot(232);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['made_cut'],\n",
    "    hue=df['made_cut'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax2\n",
    ");\n",
    "ax2.axvline(made_cut_min, linestyle = '--', color ='blue', label=f'Made Cut Min: {made_cut_min : 0.2%}');\n",
    "ax2.axvline(missed_cut_max, linestyle = '--', color ='red', label=f'Missed Cut Max: {missed_cut_max : 0.2%}');\n",
    "ax2.set_title('Scatter Plot - Made Cut');\n",
    "ax2.set_xlim(xmin, xmax);\n",
    "ax2.legend(loc='center');\n",
    "\n",
    "# Made Cut - Mean Overtime\n",
    "ax3 = fig.add_subplot(233);\n",
    "made_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Made Cut Avg.'\n",
    ");\n",
    "missed_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Missed Cut Avg.'\n",
    ");\n",
    "ax3.set_title('Average Overtime - Made Cut', {'fontsize' : 12});\n",
    "ax3.set_ylim(ymin, ymax);\n",
    "ax3.legend(loc='upper right');\n",
    "\n",
    "# Top 10 - Dist Plot\n",
    "ax4 = fig.add_subplot(234);\n",
    "sns.distplot(\n",
    "    inside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='blue',\n",
    "    ax=ax4\n",
    ");\n",
    "sns.distplot(\n",
    "    outside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='red',\n",
    "    ax=ax4\n",
    ");\n",
    "ax4.axvline(mean2_in, linestyle='--', color='blue', label=f'Inside Avg: {mean2_in : 0.2%}');\n",
    "ax4.axvline(mean2_out, linestyle='--', color='red', label=f'Outside Avg: {mean2_out : 0.2%}');\n",
    "ax4.set_title('Distribution Plot - Top 10');\n",
    "ax4.set_xlim(xmin, xmax);\n",
    "ax4.legend(loc='upper right');\n",
    "\n",
    "# Top 10 - Scatter Plot\n",
    "ax5 = fig.add_subplot(235);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['top_10'],\n",
    "    hue=df['top_10'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax5\n",
    ");\n",
    "ax5.axvline(in_t10_min, linestyle = '--', color ='blue', label=f'Inside Top 10 Min: {in_t10_min : 0.2%}');\n",
    "ax5.axvline(out_t10_max, linestyle = '--', color ='red', label=f'Outside Top 10 Max: {out_t10_max : 0.2%}');\n",
    "ax5.set_title('Scatter Plot - Top 10');\n",
    "ax5.set_xlim(xmin, xmax);\n",
    "ax5.legend(loc='center');\n",
    "\n",
    "# Top 10 - Mean Overtime\n",
    "ax6 = fig.add_subplot(236);\n",
    "inside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Inside Top 10 Avg.'\n",
    ");\n",
    "outside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Outside Top 10 Avg.'\n",
    ");\n",
    "ax6.set_title('Average Overtime - Top 10', {'fontsize' : 12});\n",
    "ax6.set_ylim(ymin, ymax);\n",
    "ax6.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Greens in Regulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "feature = 'greens_in_regulation'\n",
    "mean1_made = made_cut[feature].mean()\n",
    "mean1_missed = missed_cut[feature].mean()\n",
    "mean2_in = inside_top10[feature].mean()\n",
    "mean2_out = outside_top10[feature].mean()\n",
    "fig = plt.figure(figsize=figsize);\n",
    "fig.subplots_adjust(hspace=hspace);\n",
    "xmin = 0.5\n",
    "xmax = 0.8\n",
    "ymin = 0.62\n",
    "ymax = 0.7\n",
    "made_cut_min = df[df['made_cut']==1][feature].min()\n",
    "missed_cut_max = df[df['made_cut']==0][feature].max()\n",
    "in_t10_min = df[df['top_10']==1][feature].min()\n",
    "out_t10_max = df[df['top_10']==0][feature].max()\n",
    "\n",
    "# Made Cut - Dist Plot\n",
    "ax1 = fig.add_subplot(231);\n",
    "sns.distplot(\n",
    "    made_cut[feature], \n",
    "    bins='auto', \n",
    "    color='blue', \n",
    "    ax=ax1\n",
    ");\n",
    "sns.distplot(\n",
    "    missed_cut[feature], \n",
    "    bins='auto', \n",
    "    color='red', \n",
    "    ax=ax1\n",
    ");\n",
    "ax1.axvline(mean1_made, linestyle='--', color='blue', label=f'Made Cut Avg: {mean1_made : 0.2%}');\n",
    "ax1.axvline(mean1_missed, linestyle='--', color='red', label=f'Missed Cut Avg: {mean1_missed : 0.2%}');\n",
    "ax1.set_title('Distribution Plot - Made Cut');\n",
    "ax1.set_xlim(xmin, xmax);\n",
    "ax1.legend(loc='upper right');\n",
    "\n",
    "# Made Cut - Scatter Plot\n",
    "ax2 = fig.add_subplot(232);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['made_cut'],\n",
    "    hue=df['made_cut'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax2\n",
    ");\n",
    "ax2.axvline(made_cut_min, linestyle = '--', color ='blue', label=f'Made Cut Min: {made_cut_min : 0.2%}');\n",
    "ax2.axvline(missed_cut_max, linestyle = '--', color ='red', label=f'Missed Cut Max: {missed_cut_max : 0.2%}');\n",
    "ax2.set_title('Scatter Plot - Made Cut');\n",
    "ax2.set_xlim(xmin, xmax);\n",
    "ax2.legend(loc='center');\n",
    "\n",
    "# Made Cut - Mean Overtime\n",
    "ax3 = fig.add_subplot(233);\n",
    "made_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Made Cut Avg.'\n",
    ");\n",
    "missed_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Missed Cut Avg.'\n",
    ");\n",
    "ax3.set_title('Average Overtime - Made Cut', {'fontsize' : 12});\n",
    "ax3.set_ylim(ymin, ymax);\n",
    "ax3.legend(loc='upper left');\n",
    "\n",
    "# Top 10 - Dist Plot\n",
    "ax4 = fig.add_subplot(234);\n",
    "sns.distplot(\n",
    "    inside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='blue',\n",
    "    ax=ax4\n",
    ");\n",
    "sns.distplot(\n",
    "    outside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='red',\n",
    "    ax=ax4\n",
    ");\n",
    "ax4.axvline(mean2_in, linestyle='--', color='blue', label=f'Inside Avg: {mean2_in : 0.2%}');\n",
    "ax4.axvline(mean2_out, linestyle='--', color='red', label=f'Outside Avg: {mean2_out : 0.2%}');\n",
    "ax4.set_title('Distribution Plot - Top 10');\n",
    "ax4.set_xlim(xmin, xmax);\n",
    "ax4.legend(loc='upper right');\n",
    "\n",
    "# Top 10 - Scatter Plot\n",
    "ax5 = fig.add_subplot(235);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['top_10'],\n",
    "    hue=df['top_10'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax5\n",
    ");\n",
    "ax5.axvline(in_t10_min, linestyle = '--', color ='blue', label=f'Inside Top 10 Min: {in_t10_min : 0.2%}');\n",
    "ax5.axvline(out_t10_max, linestyle = '--', color ='red', label=f'Outside Top 10 Max: {out_t10_max : 0.2%}');\n",
    "ax5.set_title('Scatter Plot - Top 10');\n",
    "ax5.set_xlim(xmin, xmax);\n",
    "ax5.legend(loc='center');\n",
    "\n",
    "# Top 10 - Mean Overtime\n",
    "ax6 = fig.add_subplot(236);\n",
    "inside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Inside Top 10 Avg.'\n",
    ");\n",
    "outside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Outside Top 10 Avg.'\n",
    ");\n",
    "ax6.set_title('Average Overtime - Top 10', {'fontsize' : 12});\n",
    "ax6.set_ylim(ymin, ymax);\n",
    "ax6.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Par Or Better Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'par_or_better_distance'\n",
    "mean1_made = round(made_cut[feature].mean(), 1)\n",
    "mean1_missed = round(missed_cut[feature].mean(), 1)\n",
    "mean2_in = round(inside_top10[feature].mean(), 1)\n",
    "mean2_out = round(outside_top10[feature].mean(), 1)\n",
    "fig = plt.figure(figsize=figsize);\n",
    "fig.subplots_adjust(hspace=hspace);\n",
    "xmin = 14\n",
    "xmax = 24\n",
    "ymin = 18\n",
    "ymax = 21\n",
    "made_cut_min = round(df[df['made_cut']==1][feature].min(), 1)\n",
    "missed_cut_max = round(df[df['made_cut']==0][feature].max(), 1)\n",
    "in_t10_min = round(df[df['top_10']==1][feature].min(), 1)\n",
    "out_t10_max = round(df[df['top_10']==0][feature].max(), 1)\n",
    "\n",
    "# Made Cut - Dist Plot\n",
    "ax1 = fig.add_subplot(231);\n",
    "sns.distplot(\n",
    "    made_cut[feature], \n",
    "    bins='auto', \n",
    "    color='blue', \n",
    "    ax=ax1\n",
    ");\n",
    "sns.distplot(\n",
    "    missed_cut[feature], \n",
    "    bins='auto', \n",
    "    color='red', \n",
    "    ax=ax1\n",
    ");\n",
    "ax1.axvline(mean1_made, linestyle='--', color='blue', label=f'Made Cut Avg: {mean1_made}');\n",
    "ax1.axvline(mean1_missed, linestyle='--', color='red', label=f'Missed Cut Avg: {mean1_missed}');\n",
    "ax1.set_title('Distribution Plot - Made Cut');\n",
    "ax1.set_xlim(xmin, xmax);\n",
    "ax1.legend(loc='upper right');\n",
    "\n",
    "# Made Cut - Scatter Plot\n",
    "ax2 = fig.add_subplot(232);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['made_cut'],\n",
    "    hue=df['made_cut'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax2\n",
    ");\n",
    "ax2.axvline(made_cut_min, linestyle = '--', color ='blue', label=f'Made Cut Min: {made_cut_min}');\n",
    "ax2.axvline(missed_cut_max, linestyle = '--', color ='red', label=f'Missed Cut Max: {missed_cut_max}');\n",
    "ax2.set_title('Scatter Plot - Made Cut');\n",
    "ax2.set_xlim(xmin, xmax);\n",
    "ax2.legend(loc='center');\n",
    "\n",
    "# Made Cut - Mean Overtime\n",
    "ax3 = fig.add_subplot(233);\n",
    "made_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Made Cut Avg.'\n",
    ");\n",
    "missed_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Missed Cut Avg.'\n",
    ");\n",
    "ax3.set_title('Average Overtime - Made Cut', {'fontsize' : 12});\n",
    "ax3.set_ylim(ymin, ymax);\n",
    "ax3.legend(loc='upper left');\n",
    "\n",
    "# Top 10 - Dist Plot\n",
    "ax4 = fig.add_subplot(234);\n",
    "sns.distplot(\n",
    "    inside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='blue',\n",
    "    ax=ax4\n",
    ");\n",
    "sns.distplot(\n",
    "    outside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='red',\n",
    "    ax=ax4\n",
    ");\n",
    "ax4.axvline(mean2_in, linestyle='--', color='blue', label=f'Inside Avg: {mean2_in}');\n",
    "ax4.axvline(mean2_out, linestyle='--', color='red', label=f'Outside Avg: {mean2_out}');\n",
    "ax4.set_title('Distribution Plot - Top 10');\n",
    "ax4.set_xlim(xmin, xmax);\n",
    "ax4.legend(loc='upper right');\n",
    "\n",
    "# Top 10 - Scatter Plot\n",
    "ax5 = fig.add_subplot(235);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['top_10'],\n",
    "    hue=df['top_10'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax5\n",
    ");\n",
    "ax5.axvline(in_t10_min, linestyle = '--', color ='blue', label=f'Inside Top 10 Min: {in_t10_min}');\n",
    "ax5.axvline(out_t10_max, linestyle = '--', color ='red', label=f'Outside Top 10 Max: {out_t10_max}');\n",
    "ax5.set_title('Scatter Plot - Top 10');\n",
    "ax5.set_xlim(xmin, xmax);\n",
    "ax5.legend(loc='center');\n",
    "\n",
    "# Top 10 - Mean Overtime\n",
    "ax6 = fig.add_subplot(236);\n",
    "inside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Inside Top 10 Avg.'\n",
    ");\n",
    "outside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Outside Top 10 Avg.'\n",
    ");\n",
    "ax6.set_title('Average Overtime - Top 10', {'fontsize' : 12});\n",
    "ax6.set_ylim(ymin, ymax);\n",
    "ax6.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrambling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the one scramling outlier\n",
    "scram_only = df[(df['made_cut'] == 1) | ((df['made_cut'] == 0) & (df['scrambling'] < 0.68))]\n",
    "\n",
    "#Redefine sub-dataframes for correct time period\n",
    "made_cut = scram_only[scram_only['made_cut'] == 1]\n",
    "missed_cut = scram_only[scram_only['made_cut'] == 0]\n",
    "inside_top10 = scram_only[scram_only['top_10'] == 1]\n",
    "outside_top10 = scram_only[scram_only['top_10'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'scrambling'\n",
    "mean1_made = made_cut[feature].mean()\n",
    "mean1_missed = missed_cut[feature].mean()\n",
    "mean2_in = inside_top10[feature].mean()\n",
    "mean2_out = outside_top10[feature].mean()\n",
    "fig = plt.figure(figsize=figsize);\n",
    "fig.subplots_adjust(hspace=hspace);\n",
    "xmin = 0.45\n",
    "xmax = 0.75\n",
    "ymin = 0.55\n",
    "ymax = 0.62\n",
    "made_cut_min = scram_only[scram_only['made_cut']==1][feature].min()\n",
    "missed_cut_max = scram_only[scram_only['made_cut']==0][feature].max()\n",
    "in_t10_min = scram_only[scram_only['top_10']==1][feature].min()\n",
    "out_t10_max = scram_only[scram_only['top_10']==0][feature].max()\n",
    "\n",
    "# Made Cut - Dist Plot\n",
    "ax1 = fig.add_subplot(231);\n",
    "sns.distplot(\n",
    "    made_cut[feature], \n",
    "    bins='auto', \n",
    "    color='blue', \n",
    "    ax=ax1, \n",
    ");\n",
    "sns.distplot(\n",
    "    missed_cut[feature], \n",
    "    bins='auto', \n",
    "    color='red', \n",
    "    ax=ax1, \n",
    ");\n",
    "ax1.axvline(mean1_made, linestyle='--', color='blue', label=f'Made Cut Avg: {mean1_made : 0.2%}');\n",
    "ax1.axvline(mean1_missed, linestyle='--', color='red', label=f'Missed Cut Avg: {mean1_missed : 0.2%}');\n",
    "ax1.set_title('Distribution Plot - Made Cut');\n",
    "ax1.set_xlim(xmin, xmax);\n",
    "ax1.legend(loc='upper right');\n",
    "\n",
    "# Made Cut - Scatter Plot\n",
    "ax2 = fig.add_subplot(232);\n",
    "sns.scatterplot(\n",
    "    x=scram_only[feature],\n",
    "    y=scram_only['made_cut'],\n",
    "    hue=scram_only['made_cut'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax2\n",
    ");\n",
    "ax2.axvline(made_cut_min, linestyle = '--', color ='blue', label=f'Made Cut Min: {made_cut_min : 0.2%}');\n",
    "ax2.axvline(missed_cut_max, linestyle = '--', color ='red', label=f'Missed Cut Max: {missed_cut_max : 0.2%}');\n",
    "ax2.set_title('Scatter Plot - Made Cut');\n",
    "ax2.set_xlim(xmin, xmax);\n",
    "ax2.legend(loc='center');\n",
    "\n",
    "# Made Cut - Mean Overtime\n",
    "ax3 = fig.add_subplot(233);\n",
    "made_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Made Cut Avg.'\n",
    ");\n",
    "missed_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Missed Cut Avg.'\n",
    ");\n",
    "ax3.set_title('Average Overtime - Made Cut', {'fontsize' : 12});\n",
    "ax3.set_ylim(ymin, ymax);\n",
    "ax3.legend(loc='upper right');\n",
    "\n",
    "# Top 10 - Dist Plot\n",
    "ax4 = fig.add_subplot(234);\n",
    "sns.distplot(\n",
    "    inside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='blue',\n",
    "    ax=ax4\n",
    ");\n",
    "sns.distplot(\n",
    "    outside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='red',\n",
    "    ax=ax4\n",
    ");\n",
    "ax4.axvline(mean2_in, linestyle='--', color='blue', label=f'Inside Avg: {mean2_in : 0.2%}');\n",
    "ax4.axvline(mean2_out, linestyle='--', color='red', label=f'Outside Avg: {mean2_out : 0.2%}');\n",
    "ax4.set_title('Distribution Plot - Top 10');\n",
    "ax4.set_xlim(xmin, xmax);\n",
    "ax4.legend(loc='upper right');\n",
    "\n",
    "# Top 10 - Scatter Plot\n",
    "ax5 = fig.add_subplot(235);\n",
    "sns.scatterplot(\n",
    "    x=scram_only[feature],\n",
    "    y=scram_only['top_10'],\n",
    "    hue=scram_only['top_10'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax5\n",
    ");\n",
    "ax5.axvline(in_t10_min, linestyle = '--', color ='blue', label=f'Inside Top 10 Min: {in_t10_min : 0.2%}');\n",
    "ax5.axvline(out_t10_max, linestyle = '--', color ='red', label=f'Outside Top 10 Max: {out_t10_max : 0.2%}');\n",
    "ax5.set_title('Scatter Plot - Top 10');\n",
    "ax5.set_xlim(xmin, xmax);\n",
    "ax5.legend(loc='center');\n",
    "\n",
    "# Top 10 - Mean Overtime\n",
    "ax6 = fig.add_subplot(236);\n",
    "inside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Inside Top 10 Avg.'\n",
    ");\n",
    "outside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Outside Top 10 Avg.'\n",
    ");\n",
    "ax6.set_title('Average Overtime - Top 10', {'fontsize' : 12});\n",
    "ax6.set_ylim(ymin, ymax);\n",
    "ax6.legend(loc='upper right');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature = 'putting_rating'\n",
    "mean1_made = round(made_cut[feature].mean(), 1)\n",
    "mean1_missed = round(missed_cut[feature].mean(), 1)\n",
    "mean2_in = round(inside_top10[feature].mean(), 1)\n",
    "mean2_out = round(outside_top10[feature].mean(), 1)\n",
    "fig = plt.figure(figsize=figsize);\n",
    "fig.subplots_adjust(hspace=hspace);\n",
    "xmin = 0\n",
    "xmax = 400\n",
    "ymin = 150\n",
    "ymax = 250\n",
    "made_cut_max = df[df['made_cut']==1][feature].max()\n",
    "missed_cut_min = df[df['made_cut']==0][feature].min()\n",
    "in_t10_max = df[df['top_10']==1][feature].max()\n",
    "out_t10_min = df[df['top_10']==0][feature].min()\n",
    "\n",
    "# Made Cut - Dist Plot\n",
    "ax1 = fig.add_subplot(231);\n",
    "sns.distplot(\n",
    "    made_cut[feature], \n",
    "    bins='auto', \n",
    "    color='blue', \n",
    "    ax=ax1\n",
    ");\n",
    "sns.distplot(\n",
    "    missed_cut[feature], \n",
    "    bins='auto', \n",
    "    color='red', \n",
    "    ax=ax1\n",
    ");\n",
    "ax1.axvline(mean1_made, linestyle='--', color='blue', label=f'Made Cut Avg: {mean1_made}');\n",
    "ax1.axvline(mean1_missed, linestyle='--', color='red', label=f'Missed Cut Avg: {mean1_missed}');\n",
    "ax1.set_title('Distribution Plot - Made Cut');\n",
    "ax1.set_xlim(xmin, xmax);\n",
    "ax1.legend(loc='upper right');\n",
    "\n",
    "# Made Cut - Scatter Plot\n",
    "ax2 = fig.add_subplot(232);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['made_cut'],\n",
    "    hue=df['made_cut'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax2\n",
    ");\n",
    "ax2.axvline(made_cut_max, linestyle = '--', color ='blue', label=f'Made Cut Max: {made_cut_max}');\n",
    "ax2.axvline(missed_cut_min, linestyle = '--', color ='red', label=f'Missed Cut Min: {missed_cut_min}');\n",
    "ax2.set_title('Scatter Plot - Made Cut');\n",
    "ax2.set_xlim(xmin, xmax);\n",
    "ax2.legend(loc='center');\n",
    "\n",
    "# Made Cut - Mean Overtime\n",
    "ax3 = fig.add_subplot(233);\n",
    "made_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Made Cut Avg.'\n",
    ");\n",
    "missed_cut.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax3,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Missed Cut Avg.'\n",
    ");\n",
    "ax3.set_title('Average Overtime - Made Cut', {'fontsize' : 12});\n",
    "ax3.set_ylim(ymin, ymax);\n",
    "ax3.legend(loc='upper left');\n",
    "\n",
    "# Top 10 - Dist Plot\n",
    "ax4 = fig.add_subplot(234);\n",
    "sns.distplot(\n",
    "    inside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='blue',\n",
    "    ax=ax4\n",
    ");\n",
    "sns.distplot(\n",
    "    outside_top10[feature],\n",
    "    bins='auto',\n",
    "    color='red',\n",
    "    ax=ax4\n",
    ");\n",
    "ax4.axvline(mean2_in, linestyle='--', color='b', label=f'Inside Avg: {mean2_in}');\n",
    "ax4.axvline(mean2_out, linestyle='--', color='r', label=f'Outside Avg: {mean2_out}');\n",
    "ax4.set_title('Distribution Plot - Top 10');\n",
    "ax4.set_xlim(xmin, xmax);\n",
    "ax4.legend(loc='upper right');\n",
    "\n",
    "# Top 10 - Scatter Plot\n",
    "ax5 = fig.add_subplot(235);\n",
    "sns.scatterplot(\n",
    "    x=df[feature],\n",
    "    y=df['top_10'],\n",
    "    hue=df['top_10'],\n",
    "    palette=['red', 'blue'],\n",
    "    ax=ax5\n",
    ");\n",
    "ax5.axvline(in_t10_max, linestyle = '--', color ='blue', label=f'Inside Top 10 Max: {in_t10_max}');\n",
    "ax5.axvline(out_t10_min, linestyle = '--', color ='red', label=f'Outside Top 10 Min: {out_t10_min}');\n",
    "ax5.set_title('Scatter Plot - Top 10');\n",
    "ax5.set_xlim(xmin, xmax);\n",
    "ax5.legend(loc='center');\n",
    "\n",
    "# Top 10 - Mean Overtime\n",
    "ax6 = fig.add_subplot(236);\n",
    "inside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='blue',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Inside Top 10 Avg.'\n",
    ");\n",
    "outside_top10.groupby(['season'])[feature].mean().plot(\n",
    "    kind='line',\n",
    "    ax=ax6,\n",
    "    fontsize=12,\n",
    "    color='red',\n",
    "    marker='o',\n",
    "    linestyle='--',\n",
    "    label='Outside Top 10 Avg.'\n",
    ");\n",
    "ax6.set_title('Average Overtime - Top 10', {'fontsize' : 12});\n",
    "ax6.set_ylim(ymin, ymax);\n",
    "ax6.legend(loc='upper left');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('csv_files/noSG/final_golfer_data.csv', index_col=0)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Made Cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random state\n",
    "SEED = 13\n",
    "\n",
    "# Split\n",
    "test_size = 0.2\n",
    "\n",
    "# Labels\n",
    "target_names = ['missed_cut', 'made_cut']\n",
    "FI_labels = df.drop(['season', 'full_name', 'min', 'mean', 'made_cut', 'top_10', 'total_score'], axis=1).columns.values\n",
    "\n",
    "# K-folds Cross Validation\n",
    "cv = 3\n",
    "\n",
    "# Evaluation metric\n",
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['season', 'full_name', 'min', 'mean', 'made_cut', 'top_10', 'total_score'], axis=1)\n",
    "y = df['made_cut']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=SEED)\n",
    "\n",
    "# We will use smote to handle our class imbalance\n",
    "smt = SMOTE(random_state=SEED)\n",
    "X_train, y_train = smt.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_test = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = DummyClassifier(random_state = SEED)\n",
    "model_name = 'Dummy Classifier Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'strategy' : [\n",
    "        'stratified', \n",
    "        'most_frequent',\n",
    "        'prior',\n",
    "        'uniform',\n",
    "        'constant'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "dummy_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_hat_pred = dummy_clf.predict(X_train)\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = dummy_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/base_model.pkl'\n",
    "model = dummy_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = LogisticRegression(random_state=SEED)\n",
    "model_name = 'Logistic Regression Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'C' : np.logspace(-10, 10, 5),\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "log_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "log_clf.fit(X_train, y_train)\n",
    "y_hat_pred = log_clf.predict(X_train)\n",
    "y_pred = log_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = log_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/log_model.pkl'\n",
    "model = log_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = KNeighborsClassifier()\n",
    "model_name = 'KNN Model'\n",
    "\n",
    "k = int(round(np.log(X_train.shape[0]), 0))\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {'n_neighbors' : range(k,k+20,2)}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "knn_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_hat_pred = knn_clf.predict(X_train)\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = knn_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/knn_model.pkl'\n",
    "model = knn_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = DecisionTreeClassifier(random_state=SEED)\n",
    "model_name = 'Decision Tree Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : [2, 5],\n",
    "    'min_samples_split' : [5, 10],\n",
    "    'min_samples_leaf' : [5, 10]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "dt_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_hat_pred = dt_clf.predict(X_train)\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = dt_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# # Print confusion matrix\n",
    "# cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "# classes = target_names\n",
    "# plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Feature importance\n",
    "dt_optimized = DecisionTreeClassifier(\n",
    "    criterion = best_params['criterion'],\n",
    "    max_depth = best_params['max_depth'],\n",
    "    min_samples_split = best_params['min_samples_split'],\n",
    "    min_samples_leaf = best_params['min_samples_leaf'],\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "dt_optimized.fit(X_train, y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "plot_feature_importances(X_train, dt_optimized, n_features, FI_labels)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/dt_model.pkl'\n",
    "model = dt_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = RandomForestClassifier(random_state=SEED)\n",
    "model_name = 'Random Forest Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'n_estimators' : [50, 100],\n",
    "    'max_depth' : [2, 5],\n",
    "    'min_samples_split' : [5, 10],\n",
    "    'min_samples_leaf' : [5, 10]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "rf_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_hat_pred = rf_clf.predict(X_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = rf_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Feature importance\n",
    "rf_optimized = RandomForestClassifier(\n",
    "    criterion = best_params['criterion'],\n",
    "    n_estimators = best_params['n_estimators'],\n",
    "    max_depth = best_params['max_depth'],\n",
    "    min_samples_split = best_params['min_samples_split'],\n",
    "    min_samples_leaf = best_params['min_samples_leaf'],\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "plot_feature_importances(X_train, dt_optimized, n_features, FI_labels)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/rf_model.pkl'\n",
    "model = rf_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = AdaBoostClassifier(random_state=SEED)\n",
    "model_name = 'AdaBoost Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators' : [50, 100],\n",
    "    'learning_rate' : [0.1, 0.2, 0.5, 1]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "ab_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "ab_clf.fit(X_train, y_train)\n",
    "y_hat_pred = ab_clf.predict(X_train)\n",
    "y_pred = ab_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = ab_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# # Print Precision-Recall Curve\n",
    "# disp = metrics.plot_precision_recall_curve(ab_clf, X_test, y_test);\n",
    "\n",
    "# Feature importance\n",
    "ab_optimized = AdaBoostClassifier(\n",
    "    n_estimators = best_params['n_estimators'],\n",
    "    learning_rate = best_params['learning_rate'],\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "ab_optimized.fit(X_train, y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "plot_feature_importances(X_train, dt_optimized, n_features, FI_labels)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/ab_model.pkl'\n",
    "model = ab_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = GradientBoostingClassifier(random_state=SEED)\n",
    "model_name = 'Gradient Boost Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators' : [50],\n",
    "    'learning_rate' : [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "gb_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_hat_pred = gb_clf.predict(X_train)\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = gb_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Feature importance\n",
    "gb_optimized = GradientBoostingClassifier(\n",
    "    n_estimators = best_params['n_estimators'],\n",
    "    learning_rate = best_params['learning_rate'],\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "gb_optimized.fit(X_train, y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "plot_feature_importances(X_train, dt_optimized, n_features, FI_labels)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/gb_model.pkl'\n",
    "model = gb_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# # Instantiate classifier and define model\n",
    "# classifier = SVC(random_state=SEED)\n",
    "# model_name = 'Support Vector Machine Model'\n",
    "\n",
    "# # Create param grid for GridSearch\n",
    "# param_grid = {\n",
    "#     'C' : [0.1, 1, 10],\n",
    "#     'kernel' : ['linear', 'rbf', 'sigmoid'],\n",
    "#     'gamma' : [0.1, 1, 10]\n",
    "# }\n",
    "\n",
    "# # Instantiate GridSearch\n",
    "# svm_clf = GridSearchCV(\n",
    "#     classifier,\n",
    "#     param_grid,\n",
    "#     cv=cv,\n",
    "#     scoring=scoring,\n",
    "#     verbose=2,\n",
    "#     n_jobs=-1\n",
    "# )\n",
    "\n",
    "# # Fit and make predictions\n",
    "# svm_clf.fit(X_train, y_train)\n",
    "# y_hat_pred = svm_clf.predict(X_train)\n",
    "# y_pred = svm_clf.predict(X_test)\n",
    "\n",
    "# # Print Best Params\n",
    "# print('--'*27)\n",
    "# print(f'{model_name} Best Params:')\n",
    "# print('--'*27)\n",
    "# best_params = svm_clf.best_params_\n",
    "# keys = list(best_params.keys())\n",
    "# for key in keys:\n",
    "#     print(f\"{key} : {best_params[key]}\")\n",
    "\n",
    "# # Print Precision Score\n",
    "# p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "# p = metrics.precision_score(y_test, y_pred)\n",
    "# print('--'*27)\n",
    "# print(f'{model_name} Precision Scores:')\n",
    "# print('--'*27)\n",
    "# print(f' train: {p_hat : 0.2%}')\n",
    "# print(f' test: {p : 0.2%}')\n",
    "\n",
    "# # Print classification report\n",
    "# print('--'*27)\n",
    "# print(f'{model_name} Classification Report')\n",
    "# print('--'*27)\n",
    "# print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "# print('--'*27)\n",
    "\n",
    "# # Print confusion matrix\n",
    "# cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "# classes = target_names\n",
    "# plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# # Print Precision-Recall Curve\n",
    "# disp = metrics.plot_precision_recall_curve(svm_clf, X_test, y_test);\n",
    "\n",
    "# # Pickle model\n",
    "# filename = 'models/gb_model.pkl'\n",
    "# model = gb_clf\n",
    "# joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [dummy_clf, log_clf, knn_clf, dt_clf, rf_clf, ab_clf, gb_clf]\n",
    "names = ['base', 'log_reg', 'knn', 'decTree', 'randomF', 'adaB', 'gradB']\n",
    "results = []\n",
    "for index, classifier in enumerate(classifiers):\n",
    "    result = {}\n",
    "    y_hat_pred = classifier.predict(X_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    result['model'] = names[index]\n",
    "    result['accuracy_mc'] = round(metrics.accuracy_score(y_test, y_pred)*100,2)\n",
    "    result['precision_mc'] = round(metrics.precision_score(y_test, y_pred)*100,2)\n",
    "    results.append(result)\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "print(results_df.shape)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Top 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Key Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random state\n",
    "SEED = 13\n",
    "\n",
    "# Split\n",
    "test_size = 0.2\n",
    "\n",
    "# Labels\n",
    "target_names = ['outside_top_10', 'inside_top_10']\n",
    "FI_labels = df.drop(['season', 'full_name', 'min', 'mean', 'made_cut', 'top_10', 'total_score'], axis=1).columns.values\n",
    "\n",
    "# K-folds Cross Validation\n",
    "cv = 3\n",
    "\n",
    "# Evaluation metric\n",
    "scoring = 'accuracy'\n",
    "\n",
    "class_weight = [\n",
    "    'balanced',\n",
    "    {0: 0.1, 1: 0.9},\n",
    "    {0: 0.3, 1: 0.7},\n",
    "    {0: 0.5, 1: 0.5}\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train, Test, Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(['season', 'full_name', 'min', 'mean', 'made_cut', 'top_10', 'total_score'], axis=1)\n",
    "y = df['top_10']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=SEED)\n",
    "\n",
    "# # We will use smote to handle our class imbalance\n",
    "# ros = ROS(random_state=SEED)\n",
    "# X_train, y_train = ros.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()\n",
    "\n",
    "X_train = std.fit_transform(X_train)\n",
    "X_test = std.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = DummyClassifier(random_state = SEED)\n",
    "model_name = 'Dummy Classifier Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'strategy' : [\n",
    "        'stratified', \n",
    "        'most_frequent',\n",
    "        'prior',\n",
    "        'uniform',\n",
    "        'constant'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "dummy_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "y_hat_pred = dummy_clf.predict(X_train)\n",
    "y_pred = dummy_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = dummy_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/base_model.pkl'\n",
    "model = dummy_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = LogisticRegression(random_state=SEED)\n",
    "model_name = 'Logistic Regression Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'penalty' : ['l1', 'l2'],\n",
    "    'solver' : ['newton-cg', 'lbfgs', 'liblinear'],\n",
    "    'C' : np.logspace(-10, 10, 5),\n",
    "    'class_weight': class_weight\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "log_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "log_clf.fit(X_train, y_train)\n",
    "y_hat_pred = log_clf.predict(X_train)\n",
    "y_pred = log_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = log_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/log_model.pkl'\n",
    "model = log_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = KNeighborsClassifier()\n",
    "model_name = 'KNN Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'n_neighbors' : range(3,80,2),\n",
    "    'weights' : ['uniform', 'distance']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "knn_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "knn_clf.fit(X_train, y_train)\n",
    "y_hat_pred = knn_clf.predict(X_train)\n",
    "y_pred = knn_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = knn_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names = target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/knn_model.pkl'\n",
    "model = knn_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = DecisionTreeClassifier(random_state=SEED)\n",
    "model_name = 'Decision Tree Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'max_depth' : range(2, 10),\n",
    "    'min_samples_split' : range(5, 50, 5),\n",
    "    'min_samples_leaf' : range(5, 50, 5),\n",
    "    'class_weight' : class_weight\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "dt_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "dt_clf.fit(X_train, y_train)\n",
    "y_hat_pred = dt_clf.predict(X_train)\n",
    "y_pred = dt_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = dt_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# # Print confusion matrix\n",
    "# cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "# classes = target_names\n",
    "# plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Feature importance\n",
    "dt_optimized = DecisionTreeClassifier(\n",
    "    criterion = best_params['criterion'],\n",
    "    max_depth = best_params['max_depth'],\n",
    "    min_samples_split = best_params['min_samples_split'],\n",
    "    min_samples_leaf = best_params['min_samples_leaf'],\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "dt_optimized.fit(X_train, y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "plot_feature_importances(X_train, dt_optimized, n_features, FI_labels)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/dt_model.pkl'\n",
    "model = dt_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = RandomForestClassifier(random_state=SEED)\n",
    "model_name = 'Random Forest Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'criterion' : ['gini', 'entropy'],\n",
    "    'n_estimators' : [100, 200],\n",
    "    'max_depth' : [None, 2, 5, 10],\n",
    "    'min_samples_split' : [2, 5],\n",
    "    'min_samples_leaf' : [1, 5]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "rf_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "rf_clf.fit(X_train, y_train)\n",
    "y_hat_pred = rf_clf.predict(X_train)\n",
    "y_pred = rf_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = rf_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Feature importance\n",
    "rf_optimized = RandomForestClassifier(\n",
    "    criterion = best_params['criterion'],\n",
    "    n_estimators = best_params['n_estimators'],\n",
    "    max_depth = best_params['max_depth'],\n",
    "    min_samples_split = best_params['min_samples_split'],\n",
    "    min_samples_leaf = best_params['min_samples_leaf'],\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "rf_optimized.fit(X_train, y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "plot_feature_importances(X_train, dt_optimized, n_features, FI_labels)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/rf_model.pkl'\n",
    "model = rf_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = AdaBoostClassifier(random_state=SEED)\n",
    "model_name = 'AdaBoost Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators' : [100, 200, 500],\n",
    "    'learning_rate' : [0.01, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "ab_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "ab_clf.fit(X_train, y_train)\n",
    "y_hat_pred = ab_clf.predict(X_train)\n",
    "y_pred = ab_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = ab_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# # Print Precision-Recall Curve\n",
    "# disp = metrics.plot_precision_recall_curve(ab_clf, X_test, y_test);\n",
    "\n",
    "# Feature importance\n",
    "ab_optimized = AdaBoostClassifier(\n",
    "    n_estimators = best_params['n_estimators'],\n",
    "    learning_rate = best_params['learning_rate'],\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "ab_optimized.fit(X_train, y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "plot_feature_importances(X_train, dt_optimized, n_features, FI_labels)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/ab_model.pkl'\n",
    "model = ab_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate classifier and define model\n",
    "classifier = GradientBoostingClassifier(random_state=SEED)\n",
    "model_name = 'Gradient Boost Model'\n",
    "\n",
    "# Create param grid for GridSearch\n",
    "param_grid = {\n",
    "    'n_estimators' : [100, 200, 500],\n",
    "    'learning_rate' : [0.01, 0.1, 0.2, 0.5]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearch\n",
    "gb_clf = GridSearchCV(\n",
    "    classifier,\n",
    "    param_grid,\n",
    "    cv=cv,\n",
    "    scoring=scoring,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Fit and make predictions\n",
    "gb_clf.fit(X_train, y_train)\n",
    "y_hat_pred = gb_clf.predict(X_train)\n",
    "y_pred = gb_clf.predict(X_test)\n",
    "\n",
    "# Print Best Params\n",
    "print('--'*27)\n",
    "print(f'{model_name} Best Params:')\n",
    "print('--'*27)\n",
    "best_params = gb_clf.best_params_\n",
    "keys = list(best_params.keys())\n",
    "for key in keys:\n",
    "    print(f\" {key} : {best_params[key]}\")\n",
    "\n",
    "# Print Precision Score\n",
    "p_hat = metrics.precision_score(y_train, y_hat_pred)\n",
    "p = metrics.precision_score(y_test, y_pred)\n",
    "print('--'*27)\n",
    "print(f'{model_name} Precision Scores:')\n",
    "print('--'*27)\n",
    "print(f' train: {p_hat : 0.2%}')\n",
    "print(f' test: {p : 0.2%}')\n",
    "\n",
    "# Print classification report\n",
    "print('--'*27)\n",
    "print(f'{model_name} Classification Report')\n",
    "print('--'*27)\n",
    "print(metrics.classification_report(y_test, y_pred, target_names=target_names))\n",
    "print('--'*27)\n",
    "\n",
    "# Print confusion matrix\n",
    "cm = metrics.confusion_matrix(y_test, y_pred)\n",
    "classes = target_names\n",
    "plot_confusion_matrix(cm, classes)\n",
    "\n",
    "# Feature importance\n",
    "gb_optimized = GradientBoostingClassifier(\n",
    "    n_estimators = best_params['n_estimators'],\n",
    "    learning_rate = best_params['learning_rate'],\n",
    "    random_state = SEED\n",
    ")\n",
    "\n",
    "gb_optimized.fit(X_train, y_train)\n",
    "\n",
    "n_features = X_train.shape[1]\n",
    "plot_feature_importances(X_train, dt_optimized, n_features, FI_labels)\n",
    "\n",
    "# Pickle model\n",
    "filename = 'models/noSG/gb_model.pkl'\n",
    "model = gb_clf\n",
    "joblib.dump(model, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = []\n",
    "for index, classifier in enumerate(classifiers):\n",
    "    result = {}\n",
    "    y_hat_pred = classifier.predict(X_train)\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    result['model'] = names[index]\n",
    "    result['accuracy'] = round(metrics.accuracy_score(y_test, y_pred)*100,2)\n",
    "    result['precision'] = round(metrics.precision_score(y_test, y_pred)*100,2)\n",
    "    results.append(result)\n",
    "\n",
    "results_df['accuracy_t10'] = 0.00\n",
    "results_df['precision_t10'] = 0.00\n",
    "\n",
    "for i in range(len(results)):\n",
    "    results_df['accuracy_t10'].iloc[i] = results[i]['accuracy']\n",
    "    results_df['precision_t10'].iloc[i] = results[i]['precision']\n",
    "\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicitons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
